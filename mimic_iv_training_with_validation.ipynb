{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842c23c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9a206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('sepsis_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4967bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2340b815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns that start with 'latest_intubation' to start with 'time_zero'\n",
    "df.rename(\n",
    "    columns={col: col.replace('latest_intubation', 'time_4h', 1) \n",
    "             for col in df.columns if col.startswith('latest_intubation')},\n",
    "    inplace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71c0a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate mechanical power at 0 and 72 hours\n",
    "mp_0 = df['mechanical_power_0']\n",
    "mp_72 = df['mechanical_power_72hr']\n",
    "\n",
    "print(\"Mechanical Power at 0 hours:\")\n",
    "print(mp_0.describe())\n",
    "\n",
    "print(\"\\nMechanical Power at 72 hours:\")\n",
    "print(mp_72.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17a73e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define outliers as values outside 1.5*IQR from Q1 and Q3 for both timepoints\n",
    "\n",
    "def count_outliers(series):\n",
    "    q1 = series.quantile(0.25)\n",
    "    q3 =  series.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    return ((series < lower) | (series > upper)).sum()\n",
    "\n",
    "outliers_0 = count_outliers(mp_0)\n",
    "outliers_72 = count_outliers(mp_72)\n",
    "\n",
    "print(f\"Number of outliers at 0 hours: {outliers_0}\")\n",
    "print(f\"Number of outliers at 72 hours: {outliers_72}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d0de10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove entire rows where mechanical_power_0 or mechanical_power_72hr are outliers\n",
    "\n",
    "q1_0 = mp_0.quantile(0.25)\n",
    "q3_0 = mp_0.quantile(0.75)\n",
    "iqr_0 = q3_0 - q1_0\n",
    "lower_0 = q1_0 - 1.5 * iqr_0\n",
    "upper_0 = q3_0 + 1.5 * iqr_0\n",
    "\n",
    "q1_72 = mp_72.quantile(0.25)\n",
    "q3_72 = mp_72.quantile(0.75)\n",
    "iqr_72 = q3_72 - q1_72\n",
    "lower_72 = q1_72 - 1.5 * iqr_72\n",
    "upper_72 = q3_72 + 1.5 * iqr_72\n",
    "\n",
    "# Identify outlier rows for either timepoint\n",
    "outlier_rows = (\n",
    "    (df['mechanical_power_0'] < lower_0) | (df['mechanical_power_0'] > upper_0) |\n",
    "    (df['mechanical_power_72hr'] < lower_72) | (df['mechanical_power_72hr'] > upper_72)\n",
    ")\n",
    "\n",
    "# Remove the entire rows where these issues arise\n",
    "df = df[~outlier_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef01ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['gender'], prefix='gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d717a31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Use 'tracheostomy_flag' as the outcome variable\n",
    "X = df[['cumulative_vent_days', \n",
    "'age', 'gender_F', 'gender_M',\n",
    "       'mechanical_power_0', 'mechanical_power_72hr']]\n",
    "y = df['tracheostomy_flag']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e6ccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = pd.read_csv('kmimic_final.csv')\n",
    "print(len(validation))\n",
    "# Select and copy relevant columns to avoid SettingWithCopyWarning\n",
    "val = validation[['cumulative_vent_days', 'age', 'gender_F', 'gender_M', 'mech_power_4h', 'mech_power_72h', 'trach_flag']].copy()\n",
    "\n",
    "# Create new columns based on existing ones\n",
    "val['mechanical_power_0'] = val['mech_power_4h']\n",
    "val['mechanical_power_72hr'] = val['mech_power_72h']\n",
    "val['tracheostomy_flag'] = val['trach_flag']\n",
    "# x_y\n",
    "val_X = val[['cumulative_vent_days', 'age', 'gender_F', 'gender_M', 'mechanical_power_0', 'mechanical_power_72hr']]\n",
    "val_y = val['tracheostomy_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182b3f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    precision_score, accuracy_score, recall_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "\n",
    "# Initialize Random Forest with best parameters\n",
    "best_rf = RandomForestClassifier(\n",
    "    criterion='entropy',\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    n_estimators=50,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "best_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_rf = best_rf.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Random Forest - Test set accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Random Forest - Test set precision:\", precision_score(y_test, y_pred_rf))\n",
    "print(\"Random Forest - Test set recall:\", recall_score(y_test, y_pred_rf))\n",
    "print(\"\\nRandom Forest - Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n",
    "print(\"Random Forest - Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92da760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import precision_score, roc_auc_score, roc_curve, accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  # <-- Fix: import plt\n",
    "\n",
    "# Define parameter grid for randomized search\n",
    "param_dist = {\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'max_iter': [100],\n",
    "    'max_depth': [3, None],\n",
    "    'min_samples_leaf': [10],\n",
    "    'l2_regularization': [0.01, 0.1]\n",
    "}\n",
    "\n",
    "# Set up cross-validation: 5 folds, 10 repeats\n",
    "cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=10, random_state=42)\n",
    "\n",
    "# Set up the randomized search, optimizing for precision\n",
    "search = RandomizedSearchCV(\n",
    "    HistGradientBoostingClassifier(random_state=42),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    scoring='precision',\n",
    "    n_jobs=-1,\n",
    "    cv=cv,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit randomized search\n",
    "search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best parameters found:\", search.best_params_)\n",
    "print(f\"Best cross-validated precision: {search.best_score_:.3f}\")\n",
    "\n",
    "# Use the best estimator to predict\n",
    "best_skxgb = search.best_estimator_\n",
    "y_pred_skxgb = best_skxgb.predict(X_test)\n",
    "y_pred_proba_skxgb = best_skxgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate performance\n",
    "auc_skxgb = roc_auc_score(y_test, y_pred_proba_skxgb)\n",
    "acc_skxgb = accuracy_score(y_test, y_pred_skxgb)\n",
    "prec_skxgb = precision_score(y_test, y_pred_skxgb)\n",
    "print(f\"sklearn HistGradientBoosting ROC AUC: {auc_skxgb:.3f}\")\n",
    "print(f\"sklearn HistGradientBoosting Accuracy: {acc_skxgb:.3f}\")\n",
    "print(f\"sklearn HistGradientBoosting Precision: {prec_skxgb:.3f}\")\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_skxgb, tpr_skxgb, _ = roc_curve(y_test, y_pred_proba_skxgb)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_skxgb, tpr_skxgb, label=f'sklearn HistGradientBoosting (AUC = {auc_skxgb:.2f})', color='navy')\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - sklearn HistGradientBoosting')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50ee674",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_predict = best_rf.predict(val_X)\n",
    "y_val_pred_proba = best_rf.predict_proba(val_X)[:, 1]\n",
    "\n",
    "# Evaluate performance\n",
    "auc_rf = roc_auc_score(val_y, y_val_pred_proba)\n",
    "acc_rf = accuracy_score(val_y, y_val_predict)\n",
    "prec_rf = precision_score(val_y, y_val_predict)\n",
    "# print(f\"sklearn RandomForest ROC AUC: {auc_rf:.3f}\")\n",
    "# print(f\"sklearn RandomForest Accuracy: {acc_rf:.3f}\")\n",
    "# print(f\"sklearn RandomForest Precision: {prec_rf:.3f}\")\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute ROC curve for Random Forest\n",
    "fpr_rf, tpr_rf, _ = roc_curve(val_y, y_val_pred_proba)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest ROC (AUC = {auc_rf:.2f})', color='forestgreen')\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Validation ROC Curve - Random Forest')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aa0f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "from sklearn.metrics import precision_score, roc_auc_score, roc_curve, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize model with best parameters\n",
    "best_skxgb = HistGradientBoostingClassifier(\n",
    "    min_samples_leaf=10,\n",
    "    max_iter=100,\n",
    "    max_depth=None,\n",
    "    learning_rate=0.1,\n",
    "    l2_regularization=0.01,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "best_skxgb.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_skxgb = best_skxgb.predict(X_test)\n",
    "y_pred_proba_skxgb = best_skxgb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate performance\n",
    "auc_skxgb = roc_auc_score(y_test, y_pred_proba_skxgb)\n",
    "acc_skxgb = accuracy_score(y_test, y_pred_skxgb)\n",
    "prec_skxgb = precision_score(y_test, y_pred_skxgb)\n",
    "print(f\"sklearn HistGradientBoosting ROC AUC: {auc_skxgb:.3f}\")\n",
    "print(f\"sklearn HistGradientBoosting Accuracy: {acc_skxgb:.3f}\")\n",
    "print(f\"sklearn HistGradientBoosting Precision: {prec_skxgb:.3f}\")\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_skxgb, tpr_skxgb, _ = roc_curve(y_test, y_pred_proba_skxgb)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_skxgb, tpr_skxgb, label=f'sklearn HistGradientBoosting (AUC = {auc_skxgb:.2f})', color='navy')\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic - sklearn HistGradientBoosting')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caac581",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_predict = best_skxgb.predict(val_X)\n",
    "y_val_pred_proba = best_skxgb.predict_proba(val_X)[:, 1]\n",
    "\n",
    "# Evaluate performance\n",
    "auc_skxgb = roc_auc_score(val_y, y_val_pred_proba)\n",
    "acc_skxgb = accuracy_score(val_y, y_val_predict)\n",
    "prec_skxgb = precision_score(val_y, y_val_predict)\n",
    "print(f\"sklearn HistGradientBoosting ROC AUC: {auc_skxgb:.3f}\")\n",
    "print(f\"sklearn HistGradientBoosting Accuracy: {acc_skxgb:.3f}\")\n",
    "print(f\"sklearn HistGradientBoosting Precision: {prec_skxgb:.3f}\")\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Compute ROC curve\n",
    "fpr, tpr, _ = roc_curve(val_y, y_val_pred_proba)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'Validation ROC (AUC = {auc_skxgb:.2f})', color='darkorange')\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Validation ROC Curve - HistGradientBoosting')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.savefig('a.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c994d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, roc_curve, precision_score, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# HistGradientBoosting predictions on validation set\n",
    "y_val_pred_skxgb = best_skxgb.predict(val_X)\n",
    "y_val_proba_skxgb = best_skxgb.predict_proba(val_X)[:, 1]\n",
    "\n",
    "# RandomForest predictions on validation set\n",
    "y_val_pred_rf = best_rf.predict(val_X)\n",
    "y_val_proba_rf = best_rf.predict_proba(val_X)[:, 1]\n",
    "\n",
    "# ROC metrics\n",
    "fpr_skxgb, tpr_skxgb, _ = roc_curve(val_y, y_val_proba_skxgb)\n",
    "auc_skxgb = roc_auc_score(val_y, y_val_proba_skxgb)\n",
    "\n",
    "fpr_rf, tpr_rf, _ = roc_curve(val_y, y_val_proba_rf)\n",
    "auc_rf = roc_auc_score(val_y, y_val_proba_rf)\n",
    "\n",
    "# Plot both ROC curves\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_skxgb, tpr_skxgb, label=f'HistGradientBoosting (AUC = {auc_skxgb:.2f})', color='navy')\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest (AUC = {auc_rf:.2f})', color='forestgreen')\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Validation Set')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
